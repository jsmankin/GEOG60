{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GEOG 60.01** ***Practical 3: Parameterization in climate models***\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### 0. RECAP\n",
    "These past weeks, we've learned that in order to solve the energy budget more accurately that we need to consider the vertical structure of our atmosphere—its distributon of mass and temperature, and what those things imply about the conditions for getting air moving. Then we learned about chaotic determinism and convection, which laid the groundwork for understanding [**radiative-convective equilibrium**](https://texmex.mit.edu/pub/emanuel/Powerpoint/LMD_Lectures_2018/RCE_lecture_Paris_2018.pdf), namely that our planet cools itself by convecting warm moist air aloft, near space, where clouds can radiate out more efficiently. \n",
    "\n",
    "Now we're going to start to consider more complex models. In particular, we're going to think about models that simulate not just time-dependence, but spatial-dependence as well. As such, we're going to be thinking about the representation of continuous phenomena in a discretized world.\n",
    "\n",
    "<div>\n",
    "<img src=https://news.mit.edu/sites/default/files/images/201812/CliMA-2018.jpeg width=\"600\">\n",
    "<div> From: Tapio Schneider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DEFINING A CLIMATE MODEL\n",
    "\n",
    "*A representation of the exchange of energy between the Earth system and space, and its effects on average surface temperature.*\n",
    "\n",
    "(What average in space? What average in time?) \n",
    "\n",
    "Note that our focus so far has been on **planetary energy budget**. That’s the key to all climate and earth system modeling and what makes such models distinct from weather models.\n",
    "\n",
    "\n",
    "### An updated definition of a climate model might be: \n",
    "\n",
    "*A mathematical representation of the climate system. Equations are solved at points on a 3-dimensional grid in the ocean and atmosphere, over a number of time-steps.* (Just like in this image below, from MIT).\n",
    "\n",
    "Or, from [Pipitone and Easterbrook (2012)](https://gmd.copernicus.org/articles/5/1009/2012/gmd-5-1009-2012.pdf):\n",
    "\n",
    "*\"a climate model is an executable theory of the climate; the model encapsulates climatological theories in software so that they can be simulated and their implications investigated”*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 2. MODEL RESOLUTION\n",
    "We've thought a lot about $\\Delta t$, and its appropriate size given the errors that can emerge when doing calculus on a computer, and the reality that computers can only store a finite number of digits. That $\\Delta t$ is the temporal resolution, or **grain** of our model. We learned it determines the number of time steps in our **integration** or simulation, and, by extension, the global error over the **extent** of our run. \n",
    "\n",
    "Now we're going to think about the spatial resolution of our model. These models are 3-dimensional, so we need to make choices about the resolution in the $x$, $y$, and $z$ directions to render gridded volumes:\n",
    "\n",
    "<div>\n",
    "    <img src=https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/2952/2018/01/31183917/CNX_UPhysics_02_02_ijknew.jpg width=\"150\">\n",
    "<div>\n",
    "       \n",
    "On that gridded volume, our model simply solves $IN = OUT$:\n",
    "  \n",
    "<div>\n",
    "    <img src=https://ftp.comet.ucar.edu/memory-stick/tropical/textbook_2nd_edition/media/graphics/continuity.jpg width=\"300\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the term **resolution** is used to describe the degree of refinement of a climate model grid. A model with a small grid size is termed fine resolution or high resolution, while one with a large grid size is coarse resolution. Grids are becoming quite complex. Consider the hexagonal grid structure of the [MPAS model](https://sima.ucar.edu/applications/v0/mpas-cesm), which uses a [Voronoi tesselation](https://en.wikipedia.org/wiki/Voronoi_diagram) to have a high resolution domain, embedded within a coarse resolution domain:\n",
    "   \n",
    "<div>\n",
    "    <img src=https://sima.ucar.edu/sites/default/files/styles/extra_large/public/2022-11/MPAS-var-res_mesh.png?itok=qcnP873S width=\"300\">\n",
    "<div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Group discussion #1:\n",
    "\n",
    "Below is a figure quantifying the varied resolutions of the atmospheric and oceanic components of global climate models participating in CMIP5, CMIP6 and HighResMIP. Horizontal resolution (km), and (c, d) number of vertical levels. Darker-colour circles indicate high-top models (in which the top of the atmosphere is above 50 km). The crosses are the median values.\n",
    "\n",
    "**Think carefully about this figure with your neighbors. What do you notice about the differences between CMIP5 and CMIP6?**\n",
    "  \n",
    " <div>\n",
    "    <img src=https://www.ipcc.ch/report/ar6/wg1/downloads/figures/IPCC_AR6_WGI_Figure_1_19.png width=\"600\">\n",
    "<div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want you to think about the costs of these changes in model resolution these modeling groups have pursued. And I want you to think about it in the context of what we call \"resolved\" versus \"unresolved\" physics. \n",
    "\n",
    "**RESOLVED** (or grid scale processes) are large enough that they can be effectively described by the a single value in the grid box (e.g., large scale transport or a planetary wave).\n",
    "\n",
    "**UNRESOLVED** (or subgrid scale processes) are those that occur on finer scales than those effectively described by the grid box (e.g., microphysics or turbulence). \n",
    "\n",
    "**Now take a look at the log-log figure below. What do you imagine changing your spatial resolution does to your computing time? Why?**\n",
    "\n",
    "<div>\n",
    "<img src=https://ftp.comet.ucar.edu/memory-stick/tropical/textbook_2nd_edition/media/graphics/space_time_scale.jpg width=\"600\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two primary impacts of increasing resolution on computational cost: the number of grid cells will increase and the number of time steps per simulation will increase. That is because there is a deep association between lengthscales (x-axis above) and timescales (y-axis above) for physical processes. So **resolving** a process, requires considering your $\\Delta x$ in addition to your $\\Delta t$. \n",
    "\n",
    "So computationally, there are two primary impacts of increasing resolution: the number of grid cells will increase and the number of time steps per simulation will increase. \n",
    "\n",
    "If one doubles the resolution of a climate model in the horizontal, i.e. halving the grid size in each direction, *by how much does the number of total grid cells increase?* \n",
    "\n",
    "**There are cascading effects of these choices. What might they be?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a HighResMIP versus a $2^\\circ \\times 2^\\circ$ CMIP6-class model. There's about a factor 10 difference in resolution. \n",
    "\n",
    "The corresponding models would also have a factor of 10 difference in time step, which implies a factor of 100 in computational time even before taking vertical resolution into account.\n",
    "\n",
    "Let us suppose the fine resolution model has only double the vertical resolution, leading to a factor of 2000 in cost if both are run on the same domain. Thus for the same computational cost, the coarse resolution model can run a simulation 2000 times longer. For instance, the cost of running the coarse resolution model for 40 years is about the same as running the fine resolution model for 7 days. \n",
    "\n",
    "The reason that time step must be reduced when the grid size is smaller involves computational accuracy and computational instability. The time step must be small enough to accurately capture time evolution of the resolved phenomena, and for smaller grid sizes, smaller time scales tend to enter. \n",
    "\n",
    "One important time scale is the time it takes a given wind or wave speed to traverse the length of one grid box. For instance, if a wind of 50 $m s^{−1}$ is the fastest velocity in the domain of a model with 200 km grid size, the time it takes to cross one grid box is about an hour. If the time step is longer than this, more than one grid box is traversed in a single time step, so the model will not properly resolve motion of small-scale features. Small-scale noise can be artificially amplified. The model solution then becomes useless or, more often, the model “blows up,” i.e., generates enormous numbers that cause an error message in the program.\n",
    "\n",
    "For convection, its timing could be unrealistic—convective thunderstorms occur in the afternoon in Tordnado Alley, and in the evening in the Northeast. A high spatial resolution without a corresponding increase in the temporal resolution means getting the timing of convection wrong, or having it be too intermittent, and not getting physical closure.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GRID THINKING\n",
    "In climate modeling (and the data sciences more widely), we often deal with multidimensional data. By multidimensional data (also often called N-dimensional), I mean data with many independent dimensions or axes. \n",
    "\n",
    "For example, we might represent Earth’s surface temperature as a four dimensional variable:\n",
    "\n",
    "$$ T(x,y,z,t)$$\n",
    "\n",
    "where \n",
    "$x$ is longitude, \n",
    "$y$ is latitude, \n",
    "$z$ is the vertical level, and \n",
    "$t$ is time.\n",
    "\n",
    "We could even want to store multiple variables within the same dataset. \n",
    "\n",
    "Geo- and computer scientists have developed a python package called [Xarray](https://docs.xarray.dev/en/stable/getting-started-guide/why-xarray.html) that helps us keep track of the metadata and values associated with (usually gridded) high dimensional data. The point of xarray is to provide convenience for working with this type of data.\n",
    "<div>\n",
    "<img src=https://camo.githubusercontent.com/d19bddb6855355ed99d87d60975a8a85cc1807975f80a83d42912108e24e2a10/68747470733a2f2f676466612e7567722e65732f707974686f6e2f636c696d6174655f646174612f696d672f786172726179322e706e67 width=\"900\">\n",
    "<div>\n",
    "    \n",
    "We will create an Xarray tutorial for you, in case it is useful for your projects.\n",
    "    \n",
    "In the meantime, let's get a sense of it, by looking at some ESM output from [EC-EARTH3-CC](https://gmd.copernicus.org/preprints/gmd-2020-446/gmd-2020-446.pdf), which is a pretty high resolution model in the CMIP6, with about a ~60 km resolution at the equator.\n",
    " \n",
    "<div>\n",
    "<img src=https://ec-earth.org/wp-content/uploads/sites/10/2018/06/cropped-ec-earth-logo-e1528812946193-1.png width=\"150\">\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages / modules\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr #Here's our workhorse.\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 12, 6 #setting figure size\n",
    "\n",
    "import cartopy \n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set root directory\n",
    "root_dir = '/home/jovyan/shared/GEOG60/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open some data\n",
    "ds = xr.open_dataset(os.path.join(root_dir, 'prac3_ds.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Group activity***\n",
    "\n",
    "Take a moment and figure out what the dimensions of this dataset is, what variables it contains, what metadata are attached, what temporal resolution it is, e.g., the coordinates, units, etc. Make a cell below, with the command `ds` to show the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's make a quick plot of LAI**\n",
    "what projection are you?\n",
    "<div>\n",
    "<img src=https://imgs.xkcd.com/comics/map_projections.png width=\"400\">\n",
    "<div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lai for june, 2015\n",
    "\n",
    "# set ax\n",
    "ax = plt.axes(projection=ccrs.Robinson()) # what projection are we using here?\n",
    "\n",
    "# plot data\n",
    "ds['lai'].sel(time='2015-06-16').plot(ax=ax, transform=ccrs.PlateCarree(), cmap='Greens')\n",
    "# recall your dictionary tutorial. this an object, so select time and then the plot() method on the object; the data are on the rectilinear PlateCaree grid\n",
    "\n",
    "\n",
    "# title, labels\n",
    "ax.set(title='June 2015 LAI', xlabel='Lon', ylabel='Lat')\n",
    "\n",
    "# coastlines\n",
    "ax.coastlines()\n",
    "ax.add_feature(cf.BORDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing in on a grid cell from the Hanover, NH area:\n",
    "# lat and lon = 43.7 N, -72.3 E\n",
    "\n",
    "hanover_ds = ds.sel(lat=43.7, lon=(360-72.3), method='nearest')\n",
    "hanover_ds\n",
    "\n",
    "# note how 'lat' and 'lon' coords drop from the dataset dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ENTER PARAMETERIZATIONS\n",
    "The nonlinearity of weather and climate is such that there are important couplings between processes that have wide ranges of spatial and temporal scales.\n",
    "\n",
    "Discretizing continuous phenomena means we're approximating. Approximation can be viewed as implicitly or explicitly involving spatial and temporal averaging operations.\n",
    "\n",
    "Parameterizations are the subroutines in models that represent key processes without resolving them. \n",
    "\n",
    "Let's build a simple one, for the runoff of water on the land surface, just to see how complex it can get and how quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runoff Parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of runoff a simple function of precipitation $\\text P$, where you have some fraction of precipitation getting partitioned to runoff $\\text Q$ on land, maybe calculated as:\n",
    "\n",
    "$$ C = \\frac{Q}{P}$$\n",
    "\n",
    "Thus $ \\text Q$ is:\n",
    "\n",
    "$$ Q = C \\cdot P $$\n",
    "\n",
    "where:\n",
    "- $Q$ = Surface Runoff\n",
    "- $C$ = a runoff coefficient that varies with the land cover (empirically determined PARAMETER representing fraction of rain that runs off vs. infiltrates into soil)\n",
    "- $P$ = rainfall intensity\n",
    "\n",
    "Here we're using first principles and the literature to give some functional form to our little parameterization of runoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of C values based on land cover type from [Bonan's Ecological Climatology](https://www.cambridge.org/core/books/ecological-climatology/D146443B007985BC366B2512345692C0) is below.\n",
    "\n",
    "| Land cover | Range |\n",
    "| --- | --- |\n",
    "| Forest | 0.070-0.139 |\n",
    "| Grass | 0.044-0.153 |\n",
    "| Bare soil | 0.111-0.195 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-gridcell Parameterization\n",
    "\n",
    "So an EC-EARTH3-CC gridcell, despite being relatively high resolution, is quite coarse, relative to the real world. When you go outside, think about the variation in land cover just between here and your next class. Without a parameterization, all of that would be represented by a single value!\n",
    "\n",
    "Instead, models often **tile** a grid, breaking it up into smaller pieces.\n",
    "\n",
    "Let's consider subgrid scale heterogeniety in our little runoff scheme. \n",
    "\n",
    "We can use LandCoverFrac from `ds` to separate the grid cell into fractional land cover types, computing runoff for each subgrid area and then summing across them to better capture that heterogeniety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Q_i = C_i \\cdot P_i $$\n",
    "\n",
    "$$ Q = \\sum_{i=0}^{n} f_i \\cdot Q_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try implementing these methods for our \"Hanover\" gridcell. For now, let's just set each C value as the mean of its observational range from Bonan's table above:\n",
    "\n",
    "*Note: this code is certainly not written as concisely as it could be, but has been done so in order to highlight certain concepts like for loops, branching and if-statements, lists, and xarray indexing/selecting operations.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to hold (Qi * fi)'s\n",
    "subcell_q_list = []\n",
    "\n",
    "# for each of the 3 land cover types:\n",
    "for typ in hanover_ds.lctype.values:\n",
    "    \n",
    "    # set C parameter based on observations (note the use of if-statments)\n",
    "    if typ==1: # forest: set C = to 0.104 (range: 0.070-0.139)\n",
    "        cparam = 0.104\n",
    "    elif typ==2: # grass: set C = to 0.099 (range: 0.044-0.153)\n",
    "        cparam = 0.099\n",
    "    elif typ==3: # bare: set C = to 0.153 (range: 0.111-0.195)\n",
    "        cparam = 0.153\n",
    "    \n",
    "    # compute q using runoff equation (lc-specific c * precip)\n",
    "    q_i = cparam * hanover_ds['pr']\n",
    "    \n",
    "    # then scale q by fraction of grid cell that has that landcover\n",
    "    totq_subcell = q_i * hanover_ds['landCoverFrac'].sel(lctype=typ)\n",
    "    \n",
    "    # add to sub cell Q list\n",
    "    subcell_q_list.append(totq_subcell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last, sum all partial Q data\n",
    "q_da1 = (subcell_q_list[0] + subcell_q_list[1] + subcell_q_list[2])\n",
    "q_da1.name='Q'\n",
    "q_da1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot runoff timeseries:\n",
    "\n",
    "# set axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot raw data (noisy)\n",
    "q_da1.plot(ax=ax, color='grey', alpha=0.8, label='raw')\n",
    "\n",
    "# add 3-year rolling mean on top of it in blue\n",
    "q_da1.rolling(time=36).mean().plot(ax=ax, color='blue', label='3yr rolling mean')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(title='\"Hanover\" Gridcell Estimated Runoff, Method 1',\n",
    "       ylabel='Q [kg m-2 month-1]', \n",
    "       xlabel='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Challenge***\n",
    "Try plotting the contributions from each land cover type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add complexity: Compute subgrid variation in precipitation input into the land\n",
    "\n",
    "What might matter here? Certainly convective precipitation doesn't occur on 50km grids. Or even within one land cover type we might have lots of variation in the canopy structure. For example, what is the impact that leaves may have on *intercepting* some of the rainfall before it reaches the land surface? Let's consider the latter leaf issue first, and how that complicates our parameterization scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution of Leaf Area:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use a quantity called [***Leaf Area Index***](https://en.wikipedia.org/wiki/Leaf_area_index) and an equation from the CESM land surface model to represent leaf area's impact on runoff via the interception of precip. LAI is a unitless quantity that measures the amount of vegetation/leaf area per surface area - in other words, it is a measurement of vegetation density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the default Community Land Model (CLM), the intercepted fraction of precipitation by the canopy is $\\text {IF}_{i} = 1 − e^{−LAI}$, where $LAI$ is the leaf and area index of the canopy. Consequently, the incoming precipitation is reduced by a factor of $\\text {IF}_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine LAI's impact, IF\n",
    "\n",
    "def compute_interception_IF(lai):\n",
    "    \n",
    "    return 1 - np.exp(-1 * lai)\n",
    "\n",
    "# Note: this computes the fraction INTERCEPTED.  \n",
    "# So the quantity that makes it to the ground is 1 - (this function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick plot showing lai interception equation's functional form ##\n",
    "\n",
    "# gen array of lai values, 0-10\n",
    "lais = np.linspace(0,10,101)\n",
    "\n",
    "# compute IF values from lai vals using function\n",
    "IFs = compute_interception_IF(lais)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots() # initialize axis\n",
    "ax.plot(lais, IFs) # plot data\n",
    "ax.set(title='${IF}_{i} = 1 − e^{−LAI}$ Functional Form', # title & labels\n",
    "       ylabel='Fraction of Precip. Intercepted',\n",
    "       xlabel='LAI [unitless]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just use the LAI data above, but that would require the assumption that Leaf Area Index is uniformly distributed throughout the grid cell. If we wanted to continue with this theme of sub-gridcell parameterization, it follows that our various land cover classes (Forest, Grass, and Bare) would have different average LAI values. So, we can add separate LAI parameters for each land cover type:\n",
    "\n",
    "- $LAI_{bare} = 0.1$\n",
    "- $LAI_{grass} = 0.45$\n",
    "- $LAI_{forest} = 1$\n",
    "\n",
    "***Note:*** *If we were to think in terms of sensitivity, how would changing from a single LAI value for the entire cell vs. using the land cover-specific LAI values above impact the relative importance of each land cover type in determining overall runoff? Does this make sense to you intuitively?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can repeat the code from above while implement this LAI function. $P_i$ in this model now becomes a function of both Precip and LAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again, the code below is not written to be as perfectly concise as it could be.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to hold (Qi * fi)'s\n",
    "subcell_q_list2 = []\n",
    "\n",
    "# for each of the 3 land cover types:\n",
    "for typ in hanover_ds.lctype.values:\n",
    "    \n",
    "    # set c AND LAI parameters based on observations (note the use of if-statments)\n",
    "    if typ==1: # forest\n",
    "        cparam = 0.104\n",
    "        laival = 1\n",
    "    if typ==2: # grass\n",
    "        cparam = 0.099\n",
    "        laival = 0.45\n",
    "    elif typ==3: # bare\n",
    "        cparam = 0.153\n",
    "        laival = 0.1\n",
    "    \n",
    "    # compute precip that reaches the surface (it is now scaled by Lai factor)\n",
    "    precip_scaled = hanover_ds['pr'] * (1-compute_interception_IF(laival))\n",
    "    \n",
    "    # compute q using runoff equation\n",
    "    q_i = cparam * precip_scaled\n",
    "    \n",
    "    # then scale q by fraction of grid cell that has that landcover\n",
    "    totq_subcell = q_i * hanover_ds['landCoverFrac'].sel(lctype=typ)\n",
    "    \n",
    "    # add to sub cell Q list\n",
    "    subcell_q_list2.append(totq_subcell)\n",
    "\n",
    "# last, sum all partial Q data\n",
    "q_da2 = (subcell_q_list2[0] + subcell_q_list2[1] + subcell_q_list2[2])\n",
    "q_da2.name='Q'\n",
    "q_da2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add this to the plot as well. As we may expect, introducing this canopy interception scheme decreases Q across the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot runoff timeseries:\n",
    "\n",
    "# set axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot original Q\n",
    "q_da1.plot(ax=ax, color='grey', alpha=0.5, label='Method 1: raw') # raw\n",
    "q_da1.rolling(time=36).mean().plot(ax=ax, color='blue', label='Method 1: 3yr rolling mean') # rolling\n",
    "\n",
    "# plot Q method 2\n",
    "q_da2.plot(ax=ax, color='grey', alpha=0.8, label='Method 2:  raw') # raw\n",
    "q_da2.rolling(time=36).mean().plot(ax=ax, color='green', label='Method 2: 3yr rolling mean') # rolling\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(title='\"Hanover\" Gridcell Estimated Runoff, Methods 1 and 2',\n",
    "       ylabel='Q [kg m-2 month-1]', \n",
    "       xlabel='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution of precipitation intensity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps another important factor in determining runoff is ***precipitation intensity***, that is, how fast precipitation is falling. If precip is intense enough, that could also play a large role in whether or not those raindrops are intercepted by the canopy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can implement a simple parameterization developed by the Bonan and the CLM folks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because of the lack of generally robust procedures to obtain subgrid precipitation intensities from the grid cell mean forcing provided by the atmospheric model, CLM 2.0 produces an excess of canopy interception loss [Bonan et al., 2002]. When assessing the performance of runoff schemes, the fraction of precipitation reaching the soil surface needs to be as accurate as possible. A simple scheme for calculating subgrid precipitation is used in this study to reduce the excessive interception of precipitation by the canopy and thus to allow more water to reach the soil surface. The fractional area of precipitation can be estimated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f_p = \\frac{P_i + P_c}{P_i + 10 \\times P_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f_p$ = fraction of the grid cell on which precipitation falls\n",
    "- $P_i$ = large-scale precipitation\n",
    "- $P_c$ = convective precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a rainfall intensity function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rainfall_intensity_fp(Pi, Pc):\n",
    "    \n",
    "    return (Pi + Pc) / (Pi + 10*Pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and compute convective vs. large scale precipitation from our input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr is precip (all), prc is convective precip, I am assuming that all non-convective precip = large-scale precip.\n",
    "# that is:\n",
    "# Pc = 'prc' in our data\n",
    "# Pi = 'pr' - 'prc' in our data\n",
    "\n",
    "# we can do that large-scale precip computation, saving it as a new datavariable 'pr_lg' in our dataset:\n",
    "hanover_ds['pr_lg'] = hanover_ds['pr'] - hanover_ds['prc']\n",
    "hanover_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's visualize the large-scale vs. convective precip timeserieses ##\n",
    "\n",
    "fig, ax = plt.subplots() # initialize axis\n",
    "\n",
    "# plot raw data\n",
    "hanover_ds['pr_lg'].plot(ax=ax, alpha=0.4) # plot large-scale (raw data)\n",
    "hanover_ds['prc'].plot(ax=ax, alpha=0.4) # plot convective (raw data)\n",
    "\n",
    "# plot smoothed (rolling) timeserieses\n",
    "hanover_ds['pr_lg'].rolling(time=36).mean().plot(ax=ax, label='Large-Scale', color='blue') # plot large-scale \n",
    "hanover_ds['prc'].rolling(time=36).mean().plot(ax=ax, label='Convective', color='orange') # plot convective \n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set(title='\"Hanover\" Gridcell Large-Scale vs. Convective Precip',\n",
    "       ylabel='Precip [kg m-2 month-1]')\n",
    "\n",
    "# large scale precip is generally greater than convective precip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... And now for one final time let's add the next layer to our runoff parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to hold (Qi * fi)'s\n",
    "subcell_q_list3 = []\n",
    "\n",
    "# for each of the 3 land cover types:\n",
    "for typ in hanover_ds.lctype.values:\n",
    "    \n",
    "    # set c AND LAI parameters based on observations (note the use of if-statments)\n",
    "    if typ==1: # forest\n",
    "        cparam = 0.104\n",
    "        laival = 1\n",
    "    if typ==2: # grass\n",
    "        cparam = 0.099\n",
    "        laival = 0.45\n",
    "    elif typ==3: # bare\n",
    "        cparam = 0.153\n",
    "        laival = 0.1\n",
    "    \n",
    "    # compute precip that reaches the surface (it is now scaled by Lai factor AND rainfall intensity factor)\n",
    "    precip_scaled = hanover_ds['pr'] * (1-compute_interception_IF(laival)) * compute_rainfall_intensity_fp(Pi=hanover_ds['pr_lg'], Pc=hanover_ds['prc'])\n",
    "    \n",
    "    # compute q using runoff equation\n",
    "    q_i = cparam * precip_scaled\n",
    "    \n",
    "    # then scale q by fraction of grid cell that has that landcover\n",
    "    totq_subcell = q_i * hanover_ds['landCoverFrac'].sel(lctype=typ)\n",
    "    \n",
    "    # add to sub cell Q list\n",
    "    subcell_q_list3.append(totq_subcell)\n",
    "\n",
    "# last, sum all partial Q data\n",
    "q_da3 = (subcell_q_list3[0] + subcell_q_list3[1] + subcell_q_list3[2])\n",
    "q_da3.name='Q'\n",
    "q_da3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add this to the plot as well. As we may expect, introducing this canopy interception scheme decreases Q across the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot runoff timeseries:\n",
    "\n",
    "# set axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot original Q\n",
    "q_da1.plot(ax=ax, color='grey', alpha=0.5, label='Method 1: raw') # raw\n",
    "q_da1.rolling(time=36).mean().plot(ax=ax, color='blue', label='Method 1: 3yr rolling mean') # rolling\n",
    "\n",
    "# plot Q method 2\n",
    "q_da2.plot(ax=ax, color='grey', alpha=0.5, label='Method 2:  raw') # raw\n",
    "q_da2.rolling(time=36).mean().plot(ax=ax, color='green', label='Method 2: 3yr rolling mean') # rolling\n",
    "\n",
    "# plot Q method 3\n",
    "q_da3.plot(ax=ax, color='grey', alpha=0.8, label='Method 3:  raw') # raw\n",
    "q_da3.rolling(time=36).mean().plot(ax=ax, color='red', label='Method 3: 3yr rolling mean') # rolling\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(title='\"Hanover\" Gridcell Estimated Runoff, Methods 1 and 2 3',\n",
    "       ylabel='Q [kg m-2 month-1]', \n",
    "       xlabel='Time')\n",
    "\n",
    "# Now, runoff is now being scaled to nearly nothing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to do a little sensitivity analysis to assess how our parameterization of runoff varies just from one of these factions, $\\text C$ which you may recall just represents the runoff efficiency for each land cover type at the subgrid scale. Bonan gave us a range of values, and we just chose to plot the mean. What does that assumption imply for our results?\n",
    "\n",
    "What we're going to do, is we will run our parameterization 1000 times, drawing random C values from Bonan's range of values it can take on, and see how that changes the answer we get for total Hanover runoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** *The code is written differently than above in order to be more concise. It may take a few moments to run because of the number of repetitions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix to store all iterations of this sensitivity analysis\n",
    "sa_arr = np.zeros(shape=(1000, len(hanover_ds.time))) # rows = iteration, column = time\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # select values for c_forest, c_grass, and c_bare\n",
    "    c_forest = np.random.randint(low=70, high=139) * 0.001 # these lines of code are simply pulling a random number from within the\n",
    "    c_grass = np.random.randint(low=44, high=154) * 0.001 # c range noted by Bonan above.\n",
    "    c_bare = np.random.randint(low=111, high=195) * 0.001 # (am scaling by 0.001 because we had to use numpy's random INTEGER function)\n",
    "    \n",
    "    # compute q for forest:\n",
    "    # scaling incoming precip by forest interception plus rainfall intensity\n",
    "    precip_scaled = hanover_ds['pr'] * (1-compute_interception_IF(lai=1)) * compute_rainfall_intensity_fp(Pi=hanover_ds['pr_lg'], Pc=hanover_ds['prc']) \n",
    "    # precip * landcover fraction * this particular c_forest\n",
    "    forest_q = precip_scaled * hanover_ds['landCoverFrac'].sel(lctype=1) *  c_forest \n",
    "    \n",
    "    # compute q for grass\n",
    "    precip_scaled = hanover_ds['pr'] * (1-compute_interception_IF(lai=0.045)) * compute_rainfall_intensity_fp(Pi=hanover_ds['pr_lg'], Pc=hanover_ds['prc']) \n",
    "    grass_q = precip_scaled * hanover_ds['landCoverFrac'].sel(lctype=2) *  c_grass\n",
    "    \n",
    "    # compute q for bare\n",
    "    precip_scaled = hanover_ds['pr'] * (1-compute_interception_IF(lai=0.1)) * compute_rainfall_intensity_fp(Pi=hanover_ds['pr_lg'], Pc=hanover_ds['prc']) \n",
    "    bare_q = precip_scaled * hanover_ds['landCoverFrac'].sel(lctype=3) *  c_bare\n",
    "    \n",
    "    # add them\n",
    "    tot_q = (forest_q + grass_q + bare_q)\n",
    "    \n",
    "    # save in an np.array\n",
    "    sa_arr[i,:] = tot_q.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into dataArray\n",
    "sa_da = xr.DataArray(sa_arr, dims=['iter', 'time'], coords={'iter':np.array(range(1000)), 'time':hanover_ds.time})\n",
    "sa_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean, min, and max as a timeseries\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# grab mean, min, and max across the 'iteration' dimension. smooth out timeseries by taking 3yr mean\n",
    "mean_ts = sa_da.mean(dim='iter').rolling(time=36).mean()\n",
    "min_ts = sa_da.min(dim='iter').rolling(time=36).mean()\n",
    "max_ts = sa_da.max(dim='iter').rolling(time=36).mean()\n",
    "\n",
    "# plot the data\n",
    "ax.plot(mean_ts, label='Mean') # mean\n",
    "ax.fill_between(np.array(range(len(hanover_ds.time))), min_ts, max_ts, color='grey', alpha=0.4, label='Uncertainty') # fill between min & max to get uncertainty range\n",
    "\n",
    "# labels\n",
    "ax.set(title='Simple Sub-Gridcell Runoff Parameterization C-Term Uncertainty',\n",
    "       ylabel='Q [kg m-2 month]', xlabel='Month post-2015')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python nvas311",
   "language": "python",
   "name": "nvas311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
